{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import tqdm\n",
    "\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "import random\n",
    "\n",
    "class ImdbMovieReviews:\n",
    "    DEFAULT_URL = \\\n",
    "        'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "    TOKEN_REGEX = re.compile(r'[A-Za-z]+|[!?.:,()]')\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._cache_dir = './imdb'\n",
    "        self._url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "        \n",
    "        if not os.path.isfile(self._cache_dir):\n",
    "            urllib.request.urlretrieve(self._url, self._cache_dir)\n",
    "        self.filepath = self._cache_dir\n",
    "\n",
    "    def __iter__(self):\n",
    "        with tarfile.open(self.filepath) as archive:\n",
    "            items = archive.getnames()\n",
    "            for filename in archive.getnames():\n",
    "                if filename.startswith('aclImdb/train/pos/'):\n",
    "                    yield self._read(archive, filename), True\n",
    "                elif filename.startswith('aclImdb/train/neg/'):\n",
    "                    yield self._read(archive, filename), False\n",
    "                    \n",
    "    def _read(self, archive, filename):\n",
    "        with archive.extractfile(filename) as file_:\n",
    "            data = file_.read().decode('utf-8')\n",
    "            data = type(self).TOKEN_REGEX.findall(data)\n",
    "            data = [x.lower() for x in data]\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Spacy is my favourite nlp framework, which havu builtin word embeddings trains on wikipesia\n",
    "from spacy.en import English\n",
    "\n",
    "class Embedding:\n",
    "    \n",
    "    def __init__(self):\n",
    "#          spaCy makes using word vectors very easy. \n",
    "#             The Lexeme , Token , Span  and Doc  classes all have a .vector property,\n",
    "#             which is a 1-dimensional numpy array of 32-bit floats:\n",
    "#         self.parser = spacy.load('en_vectors_web_lg')\n",
    "        self.parser = English()\n",
    "#         self._length = length\n",
    "        self.dimensions = 300\n",
    "        \n",
    "    def __call__(self, sequence, length):\n",
    "        # DO I really need them to be equal length?\n",
    "        # Let's assume I'm not\n",
    "        data = np.zeros((length, self.dimensions))\n",
    "        # you can access known words from the parser's vocabulary\n",
    "        embedded = [self.parser.vocab[w].vector for w in sequence]\n",
    "        data[:len(sequence)] = embedded\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def preprocess_batched_split(iterator, embedding, batch_size):\n",
    "    iterator = iter(iterator)\n",
    "    while True:\n",
    "        batch = []\n",
    "        labelss = []\n",
    "        sentence_sizes_batch = []\n",
    "        for index in range(batch_size):\n",
    "            text, label = next(iterator)\n",
    "            sents = [list(y) for x, y in itertools.groupby(text, lambda z: z == '.') if not x]\n",
    "            sentence_sizes = [len(s) for s in sents]\n",
    "            text_embed = [embedding(sent) for sent in sents]\n",
    "            \n",
    "            batch.append(text_embed)\n",
    "            labelss.append(label)\n",
    "            sentence_sizes_batch.append(sentence_sizes)\n",
    "            \n",
    "        labels_batch = np.array(labelss, dtype=np.int32)\n",
    "        sent_per_doc = np.array([len(x) for x in sentence_sizes_batch])\n",
    "        words_per_sent_per_doc = np.array(sentence_sizes_batch)\n",
    "        yield np.array(batch), labels_batch, words_per_sent_per_doc, sent_per_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def preprocess_batched_split2(iterator, embedding, batch_size):\n",
    "    iterator = iter(iterator)\n",
    "    while True:\n",
    "        batch, labels_b = zip(*itertools.islice(iterator, batch_size))\n",
    "        \n",
    "        sents_b = [[list(y) for x, y in itertools.groupby(doc, lambda z: z == '.') if not x] for doc in batch]\n",
    "\n",
    "        sentence_sizes_b = [[len(sent) for sent in doc] for doc in sents_b]\n",
    "        sentence_size = max(map(max, sentence_sizes_b))\n",
    "        \n",
    "        document_sizes = np.array([len(doc) for doc in sentence_sizes_b], dtype=np.int32)\n",
    "        document_size = document_sizes.max()\n",
    "\n",
    "        sentence_sizes_np = np.zeros(shape=[batch_size, document_size], dtype=np.int32)\n",
    "        for bi, ds, ss in zip(range(sentence_sizes_np.shape[0]), document_sizes, sentence_sizes_b):\n",
    "            sentence_sizes_np[bi][:ds] = ss\n",
    "        \n",
    "        text_embed_b = np.zeros((batch_size, document_size, sentence_size, 300))\n",
    "        for i, ds, doc_sents in zip(range(text_embed_b.shape[0]), document_sizes, sents_b):\n",
    "            doc_sents_embed = np.array([embedding(sent, sentence_size) for sent in doc_sents])\n",
    "            text_embed_b[i][:ds] = doc_sents_embed\n",
    "        \n",
    "        yield text_embed_b, np.array(labels_b, dtype=np.int32), np.array(document_sizes), sentence_sizes_np, sents_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = list(ImdbMovieReviews())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import HanSequenceLabellingModel, model_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 1\n",
    "# %aimport HanSequenceLabellingModel, model_components\n",
    "# %aimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches_split = preprocess_batched_split2(reviews, Embedding(), batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(HanSequenceLabellingModel)\n",
    "from HanSequenceLabellingModel import HanSequenceLabellingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def HAN_model_1(session, restore_only=False):\n",
    "    \"\"\"Hierarhical Attention Network\"\"\"\n",
    "    import tensorflow as tf\n",
    "    try:\n",
    "        from tensorflow.contrib.rnn import GRUCell, MultiRNNCell, DropoutWrapper\n",
    "    except ImportError:\n",
    "        MultiRNNCell = tf.nn.rnn_cell.MultiRNNCell\n",
    "        GRUCell = tf.nn.rnn_cell.GRUCell\n",
    "    from bn_lstm import BNLSTMCell\n",
    "    from HanSequenceLabellingModel import HanSequenceLabellingModel\n",
    "\n",
    "    is_training = tf.placeholder(dtype=tf.bool, name='is_training')\n",
    "\n",
    "    cell = BNLSTMCell(80, is_training) # h-h batchnorm LSTMCell\n",
    "    cell = MultiRNNCell([cell]*5)\n",
    "\n",
    "    model = HanSequenceLabellingModel(\n",
    "            embedding_size=300,\n",
    "            classes=2,\n",
    "            word_cell=cell,\n",
    "            sentence_cell=cell,\n",
    "            word_output_size=300,\n",
    "            sentence_output_size=300,\n",
    "            learning_rate=0.001,\n",
    "            max_grad_norm=5.0,\n",
    "            dropout_keep_proba=0.5,\n",
    "            is_training=is_training,\n",
    "    )\n",
    "\n",
    "    saver = tf.train.Saver(tf.global_variables())\n",
    "    checkpoint_dir = 'checkpoints_old'\n",
    "    checkpoint = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if checkpoint:\n",
    "        print(\"Reading model parameters from %s\" % checkpoint.model_checkpoint_path)\n",
    "        saver.restore(session, checkpoint.model_checkpoint_path)\n",
    "    elif restore_only:\n",
    "        raise FileNotFoundError(\"Cannot restore model\")\n",
    "    else:\n",
    "        print(\"Created model with fresh parameters\")\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "    return model, saver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_iters = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_train = False\n",
    "if do_train:\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    config = tf.ConfigProto(gpu_options=gpu_options, allow_soft_placement=True)\n",
    "\n",
    "    with tf.Session(config=config) as s:\n",
    "        model, saver = HAN_model_1(s)\n",
    "        tflog_dir = 'tf_logs'\n",
    "        summary_writer = tf.summary.FileWriter(tflog_dir, graph=tf.get_default_graph())\n",
    "\n",
    "        for i, (data, labels_batch, sent_per_doc, words_per_sent_per_doc,_) in enumerate(batches_split):\n",
    "\n",
    "            fd = {\n",
    "                model.is_training: True,\n",
    "                model.inputs_embedded: data,\n",
    "                model.word_lengths: words_per_sent_per_doc,\n",
    "                model.sentence_lengths: sent_per_doc,\n",
    "                model.labels: labels_batch,\n",
    "                model.sample_weights: np.ones(shape=(10))\n",
    "            }\n",
    "\n",
    "            t0 = time.clock()\n",
    "            step, summaries, loss, accuracy, _ = s.run([\n",
    "                    model.global_step,\n",
    "                    model.summary,\n",
    "                    model.loss,\n",
    "                    model.accuracy,\n",
    "                    model.train_op,\n",
    "            ], feed_dict=fd)\n",
    "            td = time.clock() - t0\n",
    "\n",
    "            summary_writer.add_summary(summaries, global_step=step)\n",
    "\n",
    "            checkpoint_frequency = 100\n",
    "            eval_frequency = 1\n",
    "\n",
    "            if i >= max_iters:\n",
    "                break\n",
    "\n",
    "            if step % 1 == 0:\n",
    "                print('step %s, loss=%s, accuracy=%s, t=%s, inputs=%s' % (step, loss, accuracy, round(td, 2), fd[model.inputs_embedded].shape), end='\\r')\n",
    "            if step != 0 and step % checkpoint_frequency == 0:\n",
    "    #             print('checkpoint & graph meta')\n",
    "                checkpoint_path = 'checkpoints/checkpoint'\n",
    "                saver.save(s, checkpoint_path, global_step=step)\n",
    "    #             print('checkpoint done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copied from https://gist.github.com/christian-oudard/220521\n",
    "\n",
    "# System color name constants.\n",
    "(\n",
    "    BLACK,\n",
    "    RED,\n",
    "    GREEN,\n",
    "    YELLOW,\n",
    "    BLUE,\n",
    "    MAGENTA,\n",
    "    CYAN,\n",
    "    LIGHT_GRAY,\n",
    "    DARK_GRAY,\n",
    "    BRIGHT_RED,\n",
    "    BRIGHT_GREEN,\n",
    "    BRIGHT_YELLOW,\n",
    "    BRIGHT_BLUE,\n",
    "    BRIGHT_MAGENTA,\n",
    "    BRIGHT_CYAN,\n",
    "    WHITE,\n",
    ") = range(16)\n",
    "\n",
    "def rgb(red, green, blue):\n",
    "    \"\"\"\n",
    "    Calculate the palette index of a color in the 6x6x6 color cube.\n",
    "    The red, green and blue arguments may range from 0 to 5.\n",
    "    \"\"\"\n",
    "    return 16 + (red * 36) + (green * 6) + blue\n",
    "\n",
    "def gray(value):\n",
    "    \"\"\"\n",
    "    Calculate the palette index of a color in the grayscale ramp.\n",
    "    The value argument may range from 0 to 23.\n",
    "    \"\"\"\n",
    "    return 232 + value\n",
    "\n",
    "def set_color(fg=None, bg=None):\n",
    "    \"\"\"\n",
    "    Print escape codes to set the terminal color.\n",
    "    fg and bg are indices into the color palette for the foreground and\n",
    "    background colors.\n",
    "    \"\"\"\n",
    "    print(_set_color(fg, bg), end='')\n",
    "\n",
    "def _set_color(fg=None, bg=None):\n",
    "    result = ''\n",
    "    if fg:\n",
    "        result += '\\x1b[38;5;%dm' % fg\n",
    "    if bg:\n",
    "        result += '\\x1b[48;5;%dm' % bg\n",
    "    return result\n",
    "\n",
    "def reset_color():\n",
    "    \"\"\"\n",
    "    Reset terminal color to default.\n",
    "    \"\"\"\n",
    "    print(_reset_color(), end='')\n",
    "\n",
    "def _reset_color():\n",
    "    return '\\x1b[0m'\n",
    "\n",
    "def print_color(*args, **kwargs):\n",
    "    \"\"\"\n",
    "    Print function, with extra arguments fg and bg to set colors.\n",
    "    \"\"\"\n",
    "    fg = kwargs.pop('fg', None)\n",
    "    bg = kwargs.pop('bg', None)\n",
    "    set_color(fg, bg)\n",
    "    print(*args, **kwargs)\n",
    "    reset_color()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from checkpoints_old/checkpoint-2400\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_old/checkpoint-2400\n",
      "\u001b[48;5;198mthis \u001b[0m\u001b[48;5;198mmovie \u001b[0m\u001b[48;5;199mhas \u001b[0m\u001b[48;5;199mone \u001b[0m\u001b[48;5;200mredeeming \u001b[0m\u001b[48;5;199mfeature \u001b[0m\n",
      "\u001b[48;5;201mat \u001b[0m\u001b[48;5;201mone \u001b[0m\u001b[48;5;201mpoint \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mafter \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mcharacter \u001b[0m\u001b[48;5;201mis \u001b[0m\u001b[48;5;201mattacked \u001b[0m\u001b[48;5;201mby \u001b[0m\u001b[48;5;201man \u001b[0m\u001b[48;5;201max \u001b[0m\u001b[48;5;201mwielding \u001b[0m\u001b[48;5;201mfairy \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mhis \u001b[0m\u001b[48;5;201mbrother \u001b[0m\u001b[48;5;201masks \u001b[0m\u001b[48;5;201mhim \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mwhy \u001b[0m\u001b[48;5;201mis \u001b[0m\u001b[48;5;201myour \u001b[0m\u001b[48;5;201mdick \u001b[0m\u001b[48;5;201mover \u001b[0m\u001b[48;5;201mthere \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mchuck \u001b[0m\u001b[48;5;200m? \u001b[0m\u001b[48;5;201mafter \u001b[0m\u001b[48;5;201msuffering \u001b[0m\u001b[48;5;201mthrough \u001b[0m\u001b[48;5;201malmost \u001b[0m\u001b[48;5;201man \u001b[0m\u001b[48;5;201mhour \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;199mbad \u001b[0m\u001b[48;5;200mfilm \u001b[0m\u001b[48;5;200m, \u001b[0m\u001b[48;5;200mthis \u001b[0m\u001b[48;5;200malmost \u001b[0m\u001b[48;5;200mmade \u001b[0m\u001b[48;5;201mmy \u001b[0m\u001b[48;5;201mdrink \u001b[0m\u001b[48;5;201mcome \u001b[0m\u001b[48;5;201mout \u001b[0m\u001b[48;5;201mmy \u001b[0m\u001b[48;5;201mnose \u001b[0m\n",
      "\u001b[48;5;200mbr \u001b[0m\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201msome \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;200mthe \u001b[0m\u001b[48;5;200macting \u001b[0m\u001b[48;5;200misn \u001b[0m\u001b[48;5;200mt \u001b[0m\u001b[48;5;200mtoo \u001b[0m\u001b[48;5;199mbad \u001b[0m\u001b[48;5;199m, \u001b[0m\u001b[48;5;199mbut \u001b[0m\u001b[48;5;200mthe \u001b[0m\u001b[48;5;200mkids \u001b[0m\u001b[48;5;201mall \u001b[0m\u001b[48;5;201mstink \u001b[0m\u001b[48;5;201mand \u001b[0m\u001b[48;5;201mp \u001b[0m\n",
      "\u001b[48;5;200mj \u001b[0m\n",
      "\u001b[48;5;199msoles \u001b[0m\u001b[48;5;200mshould \u001b[0m\u001b[48;5;200mbe \u001b[0m\u001b[48;5;200mashamed \u001b[0m\u001b[48;5;200mof \u001b[0m\u001b[48;5;200mherself \u001b[0m\u001b[48;5;200mfor \u001b[0m\u001b[48;5;200mdoing \u001b[0m\u001b[48;5;200mthis \u001b[0m\u001b[48;5;199mfilm \u001b[0m\n",
      "\u001b[48;5;200mthe \u001b[0m\u001b[48;5;199mstory \u001b[0m\u001b[48;5;197mis \u001b[0m\u001b[48;5;196mweak \u001b[0m\u001b[48;5;199mand \u001b[0m\u001b[48;5;199mnobody \u001b[0m\u001b[48;5;200mdoes \u001b[0m\u001b[48;5;200mwhat \u001b[0m\u001b[48;5;200myou \u001b[0m\u001b[48;5;201mthink \u001b[0m\u001b[48;5;201m( \u001b[0m\u001b[48;5;201mor \u001b[0m\u001b[48;5;201mwhat \u001b[0m\u001b[48;5;201mcommon \u001b[0m\u001b[48;5;201msense \u001b[0m\u001b[48;5;201mdictates \u001b[0m\u001b[48;5;201m) \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mshould \u001b[0m\n",
      "\u001b[48;5;200mbr \u001b[0m\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;200mcourse \u001b[0m\u001b[48;5;200m, \u001b[0m\u001b[48;5;200mthere \u001b[0m\u001b[48;5;201mare \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mlot \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;200mstory \u001b[0m\u001b[48;5;200mpoints \u001b[0m\u001b[48;5;200mthat \u001b[0m\u001b[48;5;200mdon \u001b[0m\u001b[48;5;200mt \u001b[0m\u001b[48;5;200madd \u001b[0m\u001b[48;5;200mup \u001b[0m\n",
      "\u001b[48;5;201mfor \u001b[0m\u001b[48;5;201mexample \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201min \u001b[0m\u001b[48;5;201mone \u001b[0m\u001b[48;5;201mscene \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mghosts \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201myoung \u001b[0m\u001b[48;5;201mchildren \u001b[0m\u001b[48;5;201mmust \u001b[0m\u001b[48;5;201mconcentrate \u001b[0m\u001b[48;5;201mhard \u001b[0m\u001b[48;5;201mto \u001b[0m\u001b[48;5;201mmove \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mphysical \u001b[0m\u001b[48;5;201mobject \u001b[0m\u001b[48;5;201mso \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mcan \u001b[0m\u001b[48;5;201mprove \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mexist \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mdifficult \u001b[0m\u001b[48;5;201mfeat \u001b[0m\u001b[48;5;200msince \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mapparently \u001b[0m\u001b[48;5;201mcan \u001b[0m\u001b[48;5;201mt \u001b[0m\u001b[48;5;201minteract \u001b[0m\u001b[48;5;201mwith \u001b[0m\u001b[48;5;201mphysical \u001b[0m\u001b[48;5;201mmatter \u001b[0m\n",
      "\u001b[48;5;200mhowever \u001b[0m\u001b[48;5;199m, \u001b[0m\u001b[48;5;198mminutes \u001b[0m\u001b[48;5;200mlater \u001b[0m\u001b[48;5;200mthey \u001b[0m\u001b[48;5;201mall \u001b[0m\u001b[48;5;201mpick \u001b[0m\u001b[48;5;201mup \u001b[0m\u001b[48;5;201mbranches \u001b[0m\u001b[48;5;201moff \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mground \u001b[0m\u001b[48;5;201mand \u001b[0m\u001b[48;5;201mbeat \u001b[0m\u001b[48;5;200mthe \u001b[0m\u001b[48;5;200mtooth \u001b[0m\u001b[48;5;200mfairy \u001b[0m\u001b[48;5;200mwith \u001b[0m\u001b[48;5;200mthem \u001b[0m\n",
      "\u001b[48;5;198mapparently \u001b[0m\u001b[48;5;200mthey \u001b[0m\u001b[48;5;201mcan \u001b[0m\u001b[48;5;201msometimes \u001b[0m\u001b[48;5;201mmove \u001b[0m\u001b[48;5;200mmatter \u001b[0m\u001b[48;5;200mand \u001b[0m\u001b[48;5;200msometimes \u001b[0m\u001b[48;5;200mthey \u001b[0m\u001b[48;5;200mcan \u001b[0m\u001b[48;5;200mt \u001b[0m\n",
      "\u001b[48;5;200mgo \u001b[0m\u001b[48;5;200mfigure \u001b[0m\n",
      "\u001b[48;5;200mbr \u001b[0m\u001b[48;5;200mbr \u001b[0m\u001b[48;5;201mlots \u001b[0m\u001b[48;5;200mof \u001b[0m\u001b[48;5;200mblood \u001b[0m\u001b[48;5;200mand \u001b[0m\u001b[48;5;200mguts \u001b[0m\u001b[48;5;200m, \u001b[0m\u001b[48;5;199mthough \u001b[0m\n",
      "\u001b[48;5;200ma \u001b[0m\u001b[48;5;200mfew \u001b[0m\u001b[48;5;200mnice \u001b[0m\u001b[48;5;199mboobs \u001b[0m\n",
      "\u001b[48;5;199mbut \u001b[0m\u001b[48;5;199mthis \u001b[0m\u001b[48;5;199mdoesn \u001b[0m\u001b[48;5;200mt \u001b[0m\u001b[48;5;200mmake \u001b[0m\u001b[48;5;200mup \u001b[0m\u001b[48;5;201mfor \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mdeficiencies \u001b[0m\n",
      "\u001b[48;5;200mbr \u001b[0m\u001b[48;5;200mbr \u001b[0m\u001b[48;5;201mif \u001b[0m\u001b[48;5;201myou \u001b[0m\u001b[48;5;201mwant \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;200mmovie \u001b[0m\u001b[48;5;200mabout \u001b[0m\u001b[48;5;200mthe \u001b[0m\u001b[48;5;200mtooth \u001b[0m\u001b[48;5;200mfairy \u001b[0m\u001b[48;5;200m, \u001b[0m\u001b[48;5;200mgo \u001b[0m\u001b[48;5;200mrent \u001b[0m\u001b[48;5;200mdarkness \u001b[0m\u001b[48;5;200mfalls \u001b[0m\n",
      "\u001b[48;5;199mi \u001b[0m\u001b[48;5;200mthink \u001b[0m\u001b[48;5;199mit \u001b[0m\u001b[48;5;200ms \u001b[0m\u001b[48;5;199mgreat \u001b[0m\u001b[48;5;200m, \u001b[0m\u001b[48;5;200mthough \u001b[0m\u001b[48;5;200ma \u001b[0m\u001b[48;5;200mlot \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201mother \u001b[0m\u001b[48;5;201mreviewers \u001b[0m\u001b[48;5;201mdon \u001b[0m\u001b[48;5;201mt \u001b[0m\u001b[48;5;201mshare \u001b[0m\u001b[48;5;201mmy \u001b[0m\u001b[48;5;201mopinion \u001b[0m\n",
      "\u001b[48;5;200mat \u001b[0m\u001b[48;5;200mleast \u001b[0m\u001b[48;5;199mit \u001b[0m\u001b[48;5;200msets \u001b[0m\u001b[48;5;200ma \u001b[0m\u001b[48;5;199mmood \u001b[0m\n",
      "\n",
      "\u001b[48;5;201mthis \u001b[0m\u001b[48;5;201mmovie \u001b[0m\u001b[48;5;201mhas \u001b[0m\u001b[48;5;201mone \u001b[0m\u001b[48;5;201mredeeming \u001b[0m\u001b[48;5;201mfeature \u001b[0m\n",
      "\u001b[48;5;201mat \u001b[0m\u001b[48;5;201mone \u001b[0m\u001b[48;5;201mpoint \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mafter \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mcharacter \u001b[0m\u001b[48;5;201mis \u001b[0m\u001b[48;5;201mattacked \u001b[0m\u001b[48;5;201mby \u001b[0m\u001b[48;5;201man \u001b[0m\u001b[48;5;201max \u001b[0m\u001b[48;5;201mwielding \u001b[0m\u001b[48;5;201mfairy \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mhis \u001b[0m\u001b[48;5;201mbrother \u001b[0m\u001b[48;5;201masks \u001b[0m\u001b[48;5;201mhim \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mwhy \u001b[0m\u001b[48;5;201mis \u001b[0m\u001b[48;5;201myour \u001b[0m\u001b[48;5;201mdick \u001b[0m\u001b[48;5;201mover \u001b[0m\u001b[48;5;201mthere \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mchuck \u001b[0m\u001b[48;5;201m? \u001b[0m\u001b[48;5;201mafter \u001b[0m\u001b[48;5;201msuffering \u001b[0m\u001b[48;5;201mthrough \u001b[0m\u001b[48;5;201malmost \u001b[0m\u001b[48;5;201man \u001b[0m\u001b[48;5;201mhour \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201mbad \u001b[0m\u001b[48;5;201mfilm \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mthis \u001b[0m\u001b[48;5;201malmost \u001b[0m\u001b[48;5;201mmade \u001b[0m\u001b[48;5;201mmy \u001b[0m\u001b[48;5;201mdrink \u001b[0m\u001b[48;5;201mcome \u001b[0m\u001b[48;5;201mout \u001b[0m\u001b[48;5;201mmy \u001b[0m\u001b[48;5;201mnose \u001b[0m\n",
      "\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201msome \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201macting \u001b[0m\u001b[48;5;201misn \u001b[0m\u001b[48;5;201mt \u001b[0m\u001b[48;5;201mtoo \u001b[0m\u001b[48;5;201mbad \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mbut \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mkids \u001b[0m\u001b[48;5;201mall \u001b[0m\u001b[48;5;201mstink \u001b[0m\u001b[48;5;201mand \u001b[0m\u001b[48;5;201mp \u001b[0m\n",
      "\u001b[48;5;201mj \u001b[0m\n",
      "\u001b[48;5;201msoles \u001b[0m\u001b[48;5;201mshould \u001b[0m\u001b[48;5;201mbe \u001b[0m\u001b[48;5;201mashamed \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201mherself \u001b[0m\u001b[48;5;201mfor \u001b[0m\u001b[48;5;201mdoing \u001b[0m\u001b[48;5;201mthis \u001b[0m\u001b[48;5;201mfilm \u001b[0m\n",
      "\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mstory \u001b[0m\u001b[48;5;201mis \u001b[0m\u001b[48;5;201mweak \u001b[0m\u001b[48;5;201mand \u001b[0m\u001b[48;5;201mnobody \u001b[0m\u001b[48;5;201mdoes \u001b[0m\u001b[48;5;201mwhat \u001b[0m\u001b[48;5;201myou \u001b[0m\u001b[48;5;201mthink \u001b[0m\u001b[48;5;201m( \u001b[0m\u001b[48;5;201mor \u001b[0m\u001b[48;5;201mwhat \u001b[0m\u001b[48;5;201mcommon \u001b[0m\u001b[48;5;201msense \u001b[0m\u001b[48;5;201mdictates \u001b[0m\u001b[48;5;201m) \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mshould \u001b[0m\n",
      "\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201mcourse \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mthere \u001b[0m\u001b[48;5;201mare \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mlot \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201mstory \u001b[0m\u001b[48;5;201mpoints \u001b[0m\u001b[48;5;201mthat \u001b[0m\u001b[48;5;201mdon \u001b[0m\u001b[48;5;201mt \u001b[0m\u001b[48;5;201madd \u001b[0m\u001b[48;5;201mup \u001b[0m\n",
      "\u001b[48;5;201mfor \u001b[0m\u001b[48;5;201mexample \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201min \u001b[0m\u001b[48;5;201mone \u001b[0m\u001b[48;5;201mscene \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mghosts \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201myoung \u001b[0m\u001b[48;5;201mchildren \u001b[0m\u001b[48;5;201mmust \u001b[0m\u001b[48;5;201mconcentrate \u001b[0m\u001b[48;5;201mhard \u001b[0m\u001b[48;5;201mto \u001b[0m\u001b[48;5;201mmove \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mphysical \u001b[0m\u001b[48;5;201mobject \u001b[0m\u001b[48;5;201mso \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mcan \u001b[0m\u001b[48;5;201mprove \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mexist \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mdifficult \u001b[0m\u001b[48;5;201mfeat \u001b[0m\u001b[48;5;201msince \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mapparently \u001b[0m\u001b[48;5;201mcan \u001b[0m\u001b[48;5;201mt \u001b[0m\u001b[48;5;201minteract \u001b[0m\u001b[48;5;201mwith \u001b[0m\u001b[48;5;201mphysical \u001b[0m\u001b[48;5;201mmatter \u001b[0m\n",
      "\u001b[48;5;201mhowever \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mminutes \u001b[0m\u001b[48;5;201mlater \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mall \u001b[0m\u001b[48;5;201mpick \u001b[0m\u001b[48;5;201mup \u001b[0m\u001b[48;5;201mbranches \u001b[0m\u001b[48;5;201moff \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mground \u001b[0m\u001b[48;5;201mand \u001b[0m\u001b[48;5;201mbeat \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mtooth \u001b[0m\u001b[48;5;201mfairy \u001b[0m\u001b[48;5;201mwith \u001b[0m\u001b[48;5;201mthem \u001b[0m\n",
      "\u001b[48;5;201mapparently \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mcan \u001b[0m\u001b[48;5;201msometimes \u001b[0m\u001b[48;5;201mmove \u001b[0m\u001b[48;5;201mmatter \u001b[0m\u001b[48;5;201mand \u001b[0m\u001b[48;5;201msometimes \u001b[0m\u001b[48;5;201mthey \u001b[0m\u001b[48;5;201mcan \u001b[0m\u001b[48;5;201mt \u001b[0m\n",
      "\u001b[48;5;201mgo \u001b[0m\u001b[48;5;201mfigure \u001b[0m\n",
      "\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201mlots \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201mblood \u001b[0m\u001b[48;5;201mand \u001b[0m\u001b[48;5;201mguts \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mthough \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mfew \u001b[0m\u001b[48;5;201mnice \u001b[0m\u001b[48;5;201mboobs \u001b[0m\n",
      "\u001b[48;5;201mbut \u001b[0m\u001b[48;5;201mthis \u001b[0m\u001b[48;5;201mdoesn \u001b[0m\u001b[48;5;201mt \u001b[0m\u001b[48;5;201mmake \u001b[0m\u001b[48;5;201mup \u001b[0m\u001b[48;5;201mfor \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mdeficiencies \u001b[0m\n",
      "\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201mbr \u001b[0m\u001b[48;5;201mif \u001b[0m\u001b[48;5;201myou \u001b[0m\u001b[48;5;201mwant \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mmovie \u001b[0m\u001b[48;5;201mabout \u001b[0m\u001b[48;5;201mthe \u001b[0m\u001b[48;5;201mtooth \u001b[0m\u001b[48;5;201mfairy \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mgo \u001b[0m\u001b[48;5;201mrent \u001b[0m\u001b[48;5;201mdarkness \u001b[0m\u001b[48;5;201mfalls \u001b[0m\n",
      "\u001b[48;5;201mi \u001b[0m\u001b[48;5;201mthink \u001b[0m\u001b[48;5;201mit \u001b[0m\u001b[48;5;201ms \u001b[0m\u001b[48;5;201mgreat \u001b[0m\u001b[48;5;201m, \u001b[0m\u001b[48;5;201mthough \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mlot \u001b[0m\u001b[48;5;201mof \u001b[0m\u001b[48;5;201mother \u001b[0m\u001b[48;5;201mreviewers \u001b[0m\u001b[48;5;201mdon \u001b[0m\u001b[48;5;201mt \u001b[0m\u001b[48;5;201mshare \u001b[0m\u001b[48;5;201mmy \u001b[0m\u001b[48;5;201mopinion \u001b[0m\n",
      "\u001b[48;5;201mat \u001b[0m\u001b[48;5;201mleast \u001b[0m\u001b[48;5;201mit \u001b[0m\u001b[48;5;201msets \u001b[0m\u001b[48;5;201ma \u001b[0m\u001b[48;5;201mmood \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "\n",
    "with tf.Session(config=config) as s:\n",
    "    model, saver = HAN_model_1(s)\n",
    "    tflog_dir = 'tf_logs'\n",
    "    summary_writer = tf.summary.FileWriter(tflog_dir, graph=tf.get_default_graph())\n",
    "    \n",
    "    data, labels_batch, sent_per_doc,\\\n",
    "    words_per_sent_per_doc, sents_batch = next(batches_split)\n",
    "\n",
    "    fd = {\n",
    "        model.is_training: True,\n",
    "        model.inputs_embedded: data,\n",
    "        model.word_lengths: words_per_sent_per_doc,\n",
    "        model.sentence_lengths: sent_per_doc,\n",
    "        model.labels: labels_batch,\n",
    "        model.sample_weights: np.ones(shape=(10))\n",
    "    }\n",
    "\n",
    "    word_attentions, sentence_att = s.run([model.word_attentions, \n",
    "                                              model.sentence_attentions], \n",
    "                                             feed_dict=fd)\n",
    "    \n",
    "    sent_atts = sentence_att[0]\n",
    "    sents = sents_batch[0]\n",
    "    \n",
    "    max_sent_att = 0\n",
    "    max_word_att = 0\n",
    "    \n",
    "    for sent_index in range(len(sents)):\n",
    "        max_sent_att = max(max_sent_att, sent_atts[sent_index])\n",
    "        \n",
    "        for word_index in range(len(sents[sent_index])):\n",
    "            max_word_att = max(max_word_att, word_attentions[sent_index][word_index])\n",
    "            \n",
    "    def draw_highlighted_att(max_sent_att_loc, max_word_att_loc):\n",
    "        for sent_index in range(len(sents)):\n",
    "            for word_index in range(len(sents[sent_index])):\n",
    "                intensity = 5 - int(word_attentions[sent_index][word_index] / max_word_att_loc*5)\n",
    "                print_color(sents[sent_index][word_index], bg=rgb(5, 0, intensity), end=' ') \n",
    "            print()\n",
    "    \n",
    "    draw_highlighted_att(max_sent_att, max_word_att)\n",
    "    print()\n",
    "    draw_highlighted_att(1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from checkpoints_old/checkpoint-2400\n",
      "INFO:tensorflow:Restoring parameters from checkpoints_old/checkpoint-2400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0766c5e955a4de3b442fb977b7e3184"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[295,350,300]\n\t [[Node: word_level/word/word/word/fw/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](word_level/Reshape, word_level/word/word/word/fw/concat)]]\n\t [[Node: sentence_level/sentence/sentence/sentence/fw/fw/All/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4335_sentence_level/sentence/sentence/sentence/fw/fw/All\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'word_level/word/word/word/fw/transpose', defined at:\n  File \"/opt/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-7650e4732d01>\", line 11, in <module>\n    model, saver = HAN_model_1(sess, True)\n  File \"<ipython-input-12-a6a13d79ffb2>\", line 27, in HAN_model_1\n    is_training=is_training,\n  File \"/home/vmyrov/au_dl_course/seminar_9/homework/HanSequenceLabellingModel.py\", line 33, in __init__\n    self.word_level_output\n  File \"/opt/anaconda3/lib/python3.6/site-packages/lazy/lazy.py\", line 28, in __get__\n    value = self.__func(inst)\n  File \"/home/vmyrov/au_dl_course/seminar_9/homework/HanSequenceLabellingModel.py\", line 82, in word_level_output\n    scope=scope)\n  File \"/home/vmyrov/au_dl_course/seminar_9/homework/model_components.py\", line 24, in bidirectional_rnn\n    scope=scope))\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 405, in bidirectional_dynamic_rnn\n    time_major=time_major, scope=fw_scope)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 547, in dynamic_rnn\n    flat_input = tuple(_transpose_batch_time(input_) for input_ in flat_input)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 547, in <genexpr>\n    flat_input = tuple(_transpose_batch_time(input_) for input_ in flat_input)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 71, in _transpose_batch_time\n    ([1, 0], math_ops.range(2, x_rank)), axis=0))\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1303, in transpose\n    ret = gen_array_ops.transpose(a, perm, name=name)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3887, in transpose\n    result = _op_def_lib.apply_op(\"Transpose\", x=x, perm=perm, name=name)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[295,350,300]\n\t [[Node: word_level/word/word/word/fw/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](word_level/Reshape, word_level/word/word/word/fw/concat)]]\n\t [[Node: sentence_level/sentence/sentence/sentence/fw/fw/All/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4335_sentence_level/sentence/sentence/sentence/fw/fw/All\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[295,350,300]\n\t [[Node: word_level/word/word/word/fw/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](word_level/Reshape, word_level/word/word/word/fw/concat)]]\n\t [[Node: sentence_level/sentence/sentence/sentence/fw/fw/All/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4335_sentence_level/sentence/sentence/sentence/fw/fw/All\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7650e4732d01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         }\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_attentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_attentions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[295,350,300]\n\t [[Node: word_level/word/word/word/fw/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](word_level/Reshape, word_level/word/word/word/fw/concat)]]\n\t [[Node: sentence_level/sentence/sentence/sentence/fw/fw/All/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4335_sentence_level/sentence/sentence/sentence/fw/fw/All\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'word_level/word/word/word/fw/transpose', defined at:\n  File \"/opt/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-21-7650e4732d01>\", line 11, in <module>\n    model, saver = HAN_model_1(sess, True)\n  File \"<ipython-input-12-a6a13d79ffb2>\", line 27, in HAN_model_1\n    is_training=is_training,\n  File \"/home/vmyrov/au_dl_course/seminar_9/homework/HanSequenceLabellingModel.py\", line 33, in __init__\n    self.word_level_output\n  File \"/opt/anaconda3/lib/python3.6/site-packages/lazy/lazy.py\", line 28, in __get__\n    value = self.__func(inst)\n  File \"/home/vmyrov/au_dl_course/seminar_9/homework/HanSequenceLabellingModel.py\", line 82, in word_level_output\n    scope=scope)\n  File \"/home/vmyrov/au_dl_course/seminar_9/homework/model_components.py\", line 24, in bidirectional_rnn\n    scope=scope))\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 405, in bidirectional_dynamic_rnn\n    time_major=time_major, scope=fw_scope)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 547, in dynamic_rnn\n    flat_input = tuple(_transpose_batch_time(input_) for input_ in flat_input)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 547, in <genexpr>\n    flat_input = tuple(_transpose_batch_time(input_) for input_ in flat_input)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 71, in _transpose_batch_time\n    ([1, 0], math_ops.range(2, x_rank)), axis=0))\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1303, in transpose\n    ret = gen_array_ops.transpose(a, perm, name=name)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3887, in transpose\n    result = _op_def_lib.apply_op(\"Transpose\", x=x, perm=perm, name=name)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[295,350,300]\n\t [[Node: word_level/word/word/word/fw/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](word_level/Reshape, word_level/word/word/word/fw/concat)]]\n\t [[Node: sentence_level/sentence/sentence/sentence/fw/fw/All/_519 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_4335_sentence_level/sentence/sentence/sentence/fw/fw/All\", tensor_type=DT_BOOL, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)\n",
    "\n",
    "good_true = list()\n",
    "good_false = list()\n",
    "bad_false = list()\n",
    "bad_true = list()\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    model, saver = HAN_model_1(sess, True)\n",
    "\n",
    "    for i, (data, labels_batch, sent_per_doc, words_per_sent_per_doc, sents_b) in tqdm.tqdm_notebook(enumerate(batches_split), total=max_iters):\n",
    "        try:\n",
    "            fd = {\n",
    "                model.is_training: True,\n",
    "                model.inputs_embedded: data,\n",
    "                model.word_lengths: words_per_sent_per_doc,\n",
    "                model.sentence_lengths: sent_per_doc,\n",
    "                model.labels: labels_batch,\n",
    "                model.sample_weights: np.ones(shape=(10))\n",
    "            }\n",
    "\n",
    "            words, sentences = sess.run([model.word_attentions, model.sentence_attentions], feed_dict=fd)\n",
    "\n",
    "            for bt in range(len(sents_b)):\n",
    "                for sent_num in range(len(sents_b[bt])):\n",
    "                    for g in range(len(sents_b[bt][sent_num])):\n",
    "                        val = words[bt * len(sentences[0]) + sent_num][g]\n",
    "                        if (sents_b[bt][sent_num][g] == 'good'):\n",
    "                            if labels_batch[bt] == True:\n",
    "                                good_true.append(val)\n",
    "                            else:\n",
    "                                good_false.append(val)\n",
    "\n",
    "                        if (sents_b[bt][sent_num][g] == 'bad'):\n",
    "                            if labels_batch[bt] == True:\n",
    "                                bad_true.append(val)\n",
    "                            else:\n",
    "                                bad_false.append(val)\n",
    "                                \n",
    "            except ResourceExhaustedError:\n",
    "                print('Wow...OOM')\n",
    "                        \n",
    "        if (i >= max_iters):\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
